# Lyiv â˜•
> **Smooth Latte Gem5 Interface** - A Modern Simulation Analysis Platform

<div align="center">
  <img src="images/stuff/coffyyy.png" alt="Pixel Art Coffee Latte" width="200" height="200">
  
  [![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://python.org)
  [![React](https://img.shields.io/badge/React-18+-61DAFB.svg)](https://reactjs.org)
  [![Flask](https://img.shields.io/badge/Flask-2.0+-green.svg)](https://flask.palletsprojects.com)
  [![TypeScript](https://img.shields.io/badge/TypeScript-4.9+-3178C6.svg)](https://typescriptlang.org)
  [![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
</div>

## ğŸ¯ Overview

**Lyiv** is a sophisticated web-based gem5 simulation analyzer that transforms complex simulation data into beautiful, interactive visualizations. Built with modern web technologies, it provides researchers and developers with an intuitive interface to analyze CPU performance, memory systems, and register spill patterns.

### âœ¨ Key Features

- ğŸ¯ **Advanced Register Spill Analysis** - Deep insights into register allocation patterns
- âš¡ **Real-time Performance Metrics** - Live CPU and memory performance monitoring  
- ğŸ’¾ **Comprehensive Memory Analysis** - Memory subsystem performance and statistics
- ğŸ“ˆ **Interactive Data Visualizations** - Dynamic charts and graphs with hover tooltips
- ğŸ­ **Modern UI/UX** - Dark/light theme with glassmorphism effects
- ğŸ“Š **Live Data Updates** - Real-time data loading and display synchronization
- ğŸ“± **Responsive Design** - Optimized for desktop, tablet, and mobile devices
- ğŸ” **Detailed Tooltips** - Contextual information for every data point
- ğŸ”¥ **Thermal Heatmap Visualizations** - Register usage intensity analysis
- âš¡ **Dynamic vs Static Instruction Analysis** - Comprehensive instruction breakdown

## ğŸš€ Quick Start

### Prerequisites

Before you begin, ensure you have the following installed:

- **Python 3.7+** - Backend runtime environment
- **Node.js 14+** - Frontend development environment  
- **npm** or **yarn** - Package manager for frontend dependencies
- **Git** - Version control system

### ğŸ“¦ Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/Lyiv.git
   cd Lyiv
   ```

2. **Set up the backend environment**
   ```bash
   # Create and activate virtual environment
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   
   # Install Python dependencies
   cd backend
   pip install -r requirements.txt
   ```

3. **Set up the frontend environment**
   ```bash
   # Install Node.js dependencies
   cd frontend
   npm install
   ```

### ğŸ® Running the Application

**Step 1: Start the Backend Server**
```bash
# From the project root directory
source venv/bin/activate  # Activate virtual environment
cd backend
python simple_app.py
```

You should see the following output:
```
ğŸ® Starting Simple Gem5 Analyzer...
âœ… All data loaded successfully
ğŸš€ Starting Simple Flask server...
ğŸ“Š Backend API: http://localhost:5050
ğŸ¨ Frontend: http://localhost:8080
```

**Step 2: Start the Frontend Development Server**
```bash
# In a new terminal window
cd frontend
npm start
```

**Step 3: Access the Application**
- **Frontend Interface**: [http://localhost:8080](http://localhost:8080)
- **Backend API**: [http://localhost:5050](http://localhost:5050)

> **Note**: Ensure the `m5out/` directory contains your gem5 simulation data files (`stats.txt`, `x86_spill_stats.txt`, etc.)

## ğŸ“ Project Structure

```
Lyiv/
â”œâ”€â”€ backend/                # Flask backend server
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â”œâ”€â”€ simple_app.py       # Main Flask application
â”‚   â”œâ”€â”€ spill_visualization_generator.py # Spill chart generator
â”‚   â”œâ”€â”€ models/             # Data models
â”‚   â”œâ”€â”€ services/           # API service modules
â”‚   â”‚   â”œâ”€â”€ simple_api.py   # REST API endpoints
â”‚   â””â”€â”€ utils/              # Data processing utilities
â”‚       â”œâ”€â”€ api_helpers.py  # API helper functions
â”‚       â”œâ”€â”€ simple_reader.py # Gem5 spill log parser
â”œâ”€â”€ frontend/               # React frontend application
â”‚   â”œâ”€â”€ package.json        # Node.js dependencies
â”‚   â”œâ”€â”€ tsconfig.json       # TypeScript config
â”‚   â”œâ”€â”€ public/             # Static assets (images, index.html)
â”‚   â””â”€â”€ src/                # Source code
â”‚       â”œâ”€â”€ App.tsx         # Main React component
â”‚       â”œâ”€â”€ services/       # API client services
â”‚           â””â”€â”€ api.ts      # HTTP client configuration
â”œâ”€â”€ m5out/                  # Gem5 simulation output
â”‚   â”œâ”€â”€ stats.txt           # Simulation statistics
â”‚   â”œâ”€â”€ x86_spill_stats.txt # Register spill data
â”‚   â”œâ”€â”€ config.json         # Simulation configuration
â”‚   â””â”€â”€ fs/                 # System info (cpuinfo, stat)
â”œâ”€â”€ images/                 # Project images and graphs
â”‚   â”œâ”€â”€ graphs/             # Chart images
â”‚   â””â”€â”€ stuff/              # Misc images (coffyyy.png)
â”œâ”€â”€ run_lyiv.sh             # Automated startup script
â”œâ”€â”€ README.md               # Project documentation
â””â”€â”€ LICENSE                 # MIT License
```

## ğŸ® Usage Guide

### Automatic Data Loading
The application automatically loads and processes data from the `m5out/` directory when the backend starts.

### Web Interface Features

#### ğŸ”„ Real-time Data Updates
- Automatic data refresh and synchronization
- Live performance metrics monitoring
- Dynamic chart updates

#### ğŸ“Š Interactive Visualizations
- **Hover Tooltips**: Detailed information for every data point
- **Zoom & Pan**: Interactive charts with navigation controls
- **Theme Toggle**: Switch between dark and light modes
- **Responsive Design**: Optimized for all screen sizes

#### ğŸ¯ Data Analysis Tools
- **Register Spill Analysis**: Comprehensive spill pattern visualization
- **Performance Metrics**: CPU utilization and efficiency analysis
- **Memory System Stats**: Cache performance and memory bandwidth
- **Instruction Mix**: Detailed instruction type breakdown
- **Register Usage Heatmap**: Thermal visualization of register access patterns
- **Dynamic vs Static Analysis**: Comprehensive instruction type comparison

### Data Sources

Each metric displays its data source and calculation method:

| Metric                      | Source & API Endpoint                | Description                                      |
|-----------------------------|--------------------------------------|--------------------------------------------------|
| **Total Instructions**      | `stats.txt` â†’ `/api/basic-metrics`   | Total executed instructions                      |
| **Simulation Ticks**        | `stats.txt` â†’ `/api/basic-metrics`   | Simulation time in ticks                         |
| **Total Loads**             | `stats.txt` â†’ `/api/basic-metrics`   | Memory load operations                           |
| **Total Stores**            | `stats.txt` â†’ `/api/basic-metrics`   | Memory store operations                          |
| **Register Spills**         | `x86_spill_stats.txt` â†’ `/api/spill-analysis` | Register spill events (full streaming analysis)   |
| **Unique Memory Addresses** | `x86_spill_stats.txt` â†’ `/api/spill-analysis` | Unique addresses involved in spills              |
| **Unique Store PCs**        | `x86_spill_stats.txt` â†’ `/api/spill-analysis` | Unique store program counters                    |
| **Unique Load PCs**         | `x86_spill_stats.txt` â†’ `/api/spill-analysis` | Unique load program counters                     |
| **Spill Duration Stats**    | `x86_spill_stats.txt` â†’ `/api/spill-analysis` | Min, max, avg spill durations                    |
| **Sampled Chart Data**      | `x86_spill_stats.txt` â†’ `/api/spill-analysis` | Reservoir sample for visualizations (10,000 max) |
| **Cache Metrics**           | `stats.txt` â†’ `/api/cache-metrics`   | L1/L2/L3 cache hit/miss rates                    |
| **Instruction Mix**         | `stats.txt` â†’ `/api/instruction-types` | Breakdown of instruction types                   |
| **Efficiency Ratios**       | Calculated from `stats.txt`           | IPC, CPI, and other performance ratios           |

## ğŸ¨ Customization

### Theme Configuration
The application supports both light and dark themes with customizable color schemes:

- **Light Theme**: Clean white background with blue accents
- **Dark Theme**: Dark background with gold accents  
- **Tooltips**: Contextual styling with theme-appropriate colors
- **Glassmorphism Effects**: Modern frosted glass UI elements

### API Endpoints

The backend provides a comprehensive REST API:

| Endpoint                  | Method | Description                                                                                   |
|---------------------------|--------|-----------------------------------------------------------------------------------------------|
| `/api/basic-metrics`      | GET    | Core performance metrics from `stats.txt`                                                      |
| `/api/instruction-types`  | GET    | Instruction type breakdown from `stats.txt`                                                    |
| `/api/memory-system`      | GET    | Memory subsystem statistics from `stats.txt`                                                   |
| `/api/efficiency-metrics` | GET    | Performance efficiency data (IPC, CPI, ratios) from `stats.txt`                                |
| `/api/cache-metrics`      | GET    | Cache performance analysis (L1/L2/L3 hit/miss rates) from `stats.txt`                         |
| `/api/spill-analysis`     | GET    | Register spill analysis: full stats + sampled chart data from `x86_spill_stats.txt`            |
| `/api/spills/search`      | GET    | Streaming search over spill log (supports text, regex, wildcards, pagination)                  |
| `/api/spills/count`       | GET    | Fast count of spills matching a filter (streaming, memory-safe)                                |
| `/api/spills/sample`      | GET    | Reservoir sample of spill events for visualization (10,000 max)                                |
| `/api/spills/range`       | GET    | Range queries over spill log (by offset, line, or time)                                        |
| `/api/status`             | GET    | System status and health check                                                                |

### Configuration Options
- **Port Configuration**: Modify ports in `backend/simple_app.py` and `frontend/package.json`
- **CORS Settings**: Update allowed origins in backend configuration
- **Data Paths**: Configure gem5 output directory paths
- **Update Intervals**: Adjust data refresh rates

## ğŸ”§ Technical Architecture

### Backend Technology Stack
- **Flask**: Lightweight Python web framework
- **Pandas**: High-performance data manipulation
- **Flask-CORS**: Cross-origin resource sharing
- **Python 3.7+**: Modern Python features and performance

### Frontend Technology Stack
- **React 18+**: Modern component-based UI library
- **TypeScript**: Type-safe JavaScript development
- **Material-UI**: Professional component library
- **Recharts**: Interactive data visualization
- **Axios**: HTTP client for API communication

### Data Processing Pipeline
1. **Data Ingestion**: Parse gem5 output files (`stats.txt`, `x86_spill_stats.txt`)
2. **Data Transformation**: Convert raw data into structured metrics
3. **API Layer**: RESTful endpoints for data access
4. **Frontend Rendering**: Interactive visualizations and dashboards

### Performance Optimizations

## ğŸš€ Large-Scale Spill Data Performance Optimization

Lyiv is now optimized to handle **200 million+ spill records** efficiently!

### Key Backend Optimizations

- **Streaming Architecture**: Line-by-line file reading, O(1) memory usage
- **Reservoir Sampling**: 10,000 representative samples for large datasets
- **Adaptive Strategy**: Automatically detects dataset size and chooses optimal processing (full load for <100k, sampling for >100k)
- **Memory-Safe APIs**: All endpoints use streaming for pagination and search
- **Limited Visualization Data**: Chart data capped at 1,000 points for frontend performance

### Performance Benchmarks

| Metric                | Before   | After   | Improvement         |
|-----------------------|----------|---------|---------------------|
| Memory Usage (200M)   | 40GB+    | 100MB   | 400x reduction âš¡   |
| Processing Time (200M)| Hours    | 45-60s  | >100x faster âš¡     |
| Chart Data Points     | 200M     | 1,000   | 200,000x reduction |

### API Usage for Large Datasets


- `/api/spill-analysis` â€” Returns full statistics (always accurate) and a sampled dataset for charts (auto-sampling for large files)
- `/api/spills/search` â€” Streaming, paginated search with support for text, regex, wildcards, offset, and limit
- `/api/spills/count` â€” Fast, memory-safe counting of spills matching any filter (streaming, no memory overhead)
- `/api/spills/sample` â€” Returns a random reservoir sample of spill events (up to 10,000) for visualization
- `/api/spills/range` â€” Range queries by offset, line, or time (streaming, efficient for large files)

### Configuration

You can tune performance and sampling behavior in `backend/utils/simple_reader.py`:

```python
SAMPLE_SIZE = 10000      # Number of events to sample for chart visualizations (used only for large datasets)
max_events = 50000       # If total events â‰¤ max_events, load all events for analysis and charts (no sampling)
LARGE_THRESHOLD = 100000 # If total events > LARGE_THRESHOLD, switch to sampling mode for charts
```
Recommended values:
- For very large datasets, reduce `SAMPLE_SIZE` for faster chart rendering
- Increase `max_events` if you have more memory and want full analysis for larger files
- Adjust `LARGE_THRESHOLD` to control when sampling is triggered

### Testing

Run the included test script:

```bash
python test_optimization.py
```


### Documentation

All optimization details, usage guides, and test scripts are now included in this README.

## ğŸ› Troubleshooting

### Common Issues & Solutions

#### Port Configuration Problems
```bash
# Check if ports are in use
lsof -i :5050  # Backend port
lsof -i :8080  # Frontend port

# Kill processes using ports
lsof -ti:5050 | xargs kill -9
lsof -ti:8080 | xargs kill -9
```

#### Data Loading Issues
- **Missing Data Files**: Ensure `m5out/` directory contains required files
- **Permission Errors**: Check file permissions for data files
- **Path Issues**: Verify relative paths in configuration

#### Development Environment
- **Virtual Environment**: Always activate Python virtual environment
- **Node Modules**: Run `npm install` after cloning repository
- **Dependencies**: Update packages with `pip install -r requirements.txt`


### Getting Help
- **Check Logs**: Review backend console output for error messages
- **API Testing**: Use `curl` or Postman to test API endpoints directly
- **Browser Console**: Inspect frontend errors and network requests


### ğŸ“‹ How to Contribute
1. **Fork the repository** and create a feature branch
2. **Make your changes** with clear commit messages
3. **Test thoroughly** to ensure functionality
4. **Submit a pull request** with a detailed description

### ğŸ¯ Development Guidelines
- Follow existing code style and conventions
- Add appropriate error handling and logging
- Update documentation for new features
- Ensure cross-browser compatibility

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.


### API Endpoints Still Functional

All streaming endpoints remain fully functional:
- `/api/spills/search` - Paginated search with streaming
- `/api/spills/count` - Fast count with optional limit
- `/api/spill-analysis` - Now uses optimized sampling

### Configuration

You can adjust sampling parameters in `simple_reader.py`:

ğŸ›‘ Please note that the following parameters are set only for visual graphics and do not affect the accuracy of the core statistics, which are always computed from the full dataset. ğŸ›‘

```python
# Line ~1175: Adjust sample size
SAMPLE_SIZE = 10000  # Default: 10k events for analysis

# Line ~50: Adjust max events for small datasets
max_events: int = 50000  # Default: 50k max for full load

# Line ~1120: Adjust large dataset threshold
if total_spills > 100000:  # Default: 100k threshold
```

### Usage Example

```python
# Backend automatically handles optimization
reader = SimpleGem5Reader(m5out_path)
analysis = reader.get_spill_analysis_data()

# Response includes metadata
print(f"Total spills: {analysis['spill_count']:,}")
print(f"Sampled: {analysis['sampled']}")
print(f"Processing time: {analysis['performance']['processing_time_seconds']}s")
```


---

## ğŸ› ï¸ Automated Project Startup

You can use the provided shell script `run_lyiv.sh` to automate the setup and running of Lyiv:

### Usage

```bash
chmod +x run_lyiv.sh
./run_lyiv.sh
```

**What this script does:**
1. Copies the `m5out` directory from your gem5 results into the Lyiv project.
2. Activates the Python virtual environment.
3. Runs the test script (`test_optimization.py`) to verify analysis.
4. Asks if you want to proceed:
   - If you answer `y` or `Y`, it starts both backend and frontend servers automatically.
   - If you answer `n` or `N`, it terminates the process.
   - For any other input, it asks again until you answer `y` or `n`.

**Example output:**
```
âœ… m5out successfully copied to Lyiv/m5out.
âœ… Virtual environment activated.
Running test_optimization.py...
Do you want to proceed and run backend & frontend? (y/n):
```

This script streamlines the workflow for quickly setting up and running Lyiv with your latest gem5 simulation data.



## ğŸ¤ Contributing

We welcome contributions to improve Lyiv! Here are some areas where you can help:


---

<div align="center">
  <strong>Enjoy analyzing your gem5 simulations with this smooth and modern interface! â˜•ğŸ®âœ¨</strong>
  
  <br><br>
  
  <em>Made with â˜• and â¤ï¸ for the computer architecture research lab (CAST)</em>
</div>
