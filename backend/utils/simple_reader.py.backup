#!/usr/bin/env python3
"""
📊 Simple Gem5 Data Reader 📊
============================

Simple data reader for basic gem5 metrics without complex analysis.
"""

import os
import pandas as pd
import json
from typing import Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class SimpleGem5Reader:
    """Simple reader for basic gem5 metrics"""
    
    def __init__(self, m5out_path: str):
        self.m5out_path = m5out_path
        self.stats_data = {}
        
    def read_all_data(self) -> bool:
        """Read all data from m5out directory"""
        try:
            # Read stats.txt
            stats_file = os.path.join(self.m5out_path, "stats.txt")
            if os.path.exists(stats_file):
                self._read_stats_file(stats_file)
                logger.info("✅ Stats data read successfully")
            else:
                logger.warning("⚠️ stats.txt not found")
            
            logger.info("ℹ️ Working with stats.txt only")
                
            return True
        except Exception as e:
            logger.error(f"❌ Error reading data: {e}")
            return False
    
    def _read_stats_file(self, file_path: str) -> None:
        """Read stats.txt file"""
        self.stats_data = {}
        
        try:
            with open(file_path, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        # Parse format: name value # description
                        parts = line.split('#')
                        if len(parts) >= 1:
                            name_value = parts[0].strip()
                            
                            # Extract name and value
                            name_value_parts = name_value.split()
                            if len(name_value_parts) >= 2:
                                name = name_value_parts[0]
                                value = name_value_parts[1]
                                self.stats_data[name] = value
        except Exception as e:
            logger.error(f"Error reading stats file: {e}")
    
    
    def get_basic_metrics(self) -> Dict[str, Any]:
        """Get basic metrics for frontend"""
        metrics = {}
        
        # Total instructions
        total_insts = self._get_stat_value('system.cpu.commitStats0.numInsts', int)
        metrics['total_instructions'] = total_insts or 0
        
        # Total ticks
        total_ticks = self._get_stat_value('simTicks', int)
        metrics['total_ticks'] = total_ticks or 0
        
        # Simulation timing
        sim_seconds = self._get_stat_value('simSeconds', float)
        host_seconds = self._get_stat_value('hostSeconds', float)
        host_tick_rate = self._get_stat_value('hostTickRate', int)
        host_inst_rate = self._get_stat_value('hostInstRate', int)
        
        metrics['sim_seconds'] = round(sim_seconds or 0, 6)
        metrics['host_seconds'] = round(host_seconds or 0, 6)
        metrics['host_tick_rate'] = host_tick_rate or 0
        metrics['host_inst_rate'] = host_inst_rate or 0
        
        # Simulation vs Host performance
        if sim_seconds and sim_seconds > 0:
            metrics['simulation_speedup'] = round((host_seconds or 0) / sim_seconds, 2)
        else:
            metrics['simulation_speedup'] = 0
        
        # Total loads
        total_loads = self._get_stat_value('system.cpu.commitStats0.numLoadInsts', int)
        metrics['total_loads'] = total_loads or 0
        
        # Total stores
        total_stores = self._get_stat_value('system.cpu.commitStats0.numStoreInsts', int)
        metrics['total_stores'] = total_stores or 0
        
        # Instruction breakdown
        sim_insts = self._get_stat_value('simInsts', int)
        sim_ops = self._get_stat_value('simOps', int)
        committed_ops = self._get_stat_value('system.cpu.commitStats0.numOps', int)
        committed_insts_not_nop = self._get_stat_value('system.cpu.commitStats0.numInstsNotNOP', int)
        committed_ops_not_nop = self._get_stat_value('system.cpu.commitStats0.numOpsNotNOP', int)
        
        metrics['sim_insts'] = sim_insts or 0
        metrics['sim_ops'] = sim_ops or 0
        metrics['committed_ops'] = committed_ops or 0
        metrics['committed_insts_not_nop'] = committed_insts_not_nop or 0
        metrics['committed_ops_not_nop'] = committed_ops_not_nop or 0
        
        # Instruction type counts
        fp_insts = self._get_stat_value('system.cpu.commitStats0.numFpInsts', int)
        int_insts = self._get_stat_value('system.cpu.commitStats0.numIntInsts', int)
        vec_insts = self._get_stat_value('system.cpu.commitStats0.numVecInsts', int)
        
        metrics['fp_insts'] = fp_insts or 0
        metrics['int_insts'] = int_insts or 0
        metrics['vec_insts'] = vec_insts or 0
        
        # Total cycles
        total_cycles = self._get_stat_value('system.cpu.numCycles', int)
        metrics['total_cycles'] = total_cycles or 0
        
        # CPI and IPC
        cpi = self._get_stat_value('system.cpu.cpi', float)
        ipc = self._get_stat_value('system.cpu.ipc', float)
        metrics['cpi'] = cpi or 0
        metrics['ipc'] = ipc or 0
        
        # Register usage
        int_reg_reads = self._get_stat_value('system.cpu.executeStats0.numIntRegReads', int)
        int_reg_writes = self._get_stat_value('system.cpu.executeStats0.numIntRegWrites', int)
        fp_reg_reads = self._get_stat_value('system.cpu.executeStats0.numFpRegReads', int)
        fp_reg_writes = self._get_stat_value('system.cpu.executeStats0.numFpRegWrites', int)
        
        metrics['int_reg_reads'] = int_reg_reads or 0
        metrics['int_reg_writes'] = int_reg_writes or 0
        metrics['fp_reg_reads'] = fp_reg_reads or 0
        metrics['fp_reg_writes'] = fp_reg_writes or 0
        
        # Memory references
        total_mem_refs = self._get_stat_value('system.cpu.executeStats0.numMemRefs', int)
        metrics['total_memory_refs'] = total_mem_refs or 0
        
        # Binary and architecture information
        metrics['binary_info'] = self._get_binary_info()
        
        # Calculate percentages
        if total_insts and total_insts > 0:
            metrics['load_percentage'] = (total_loads / total_insts) * 100
            metrics['store_percentage'] = (total_stores / total_insts) * 100
            metrics['memory_ref_percentage'] = (total_mem_refs / total_insts) * 100
        else:
            metrics['load_percentage'] = 0
            metrics['store_percentage'] = 0
            metrics['memory_ref_percentage'] = 0
        
        return metrics
    
    def get_instruction_types(self) -> Dict[str, Any]:
        """Get instruction type distribution"""
        instruction_types = {}
        total_instructions = 0
        
        # First pass: collect all instruction types and calculate total
        for key, value in self.stats_data.items():
            if 'committedInstType::' in key and 'total' not in key:
                inst_type = key.split('::')[-1]
                try:
                    count = int(value)
                    if count > 0:
                        instruction_types[inst_type] = count
                        total_instructions += count
                except (ValueError, TypeError):
                    pass
        
        # Second pass: add percentages
        if total_instructions > 0:
            for inst_type in instruction_types:
                percentage = (instruction_types[inst_type] / total_instructions) * 100
                instruction_types[inst_type] = {
                    'count': instruction_types[inst_type],
                    'percentage': round(percentage, 2)
                }
        
        # Add metadata
        result = {
            'instruction_types': instruction_types,
            'total_instructions': total_instructions,
            'architecture': self._detect_architecture()
        }
        
        return result
    
    def get_efficiency_metrics(self) -> Dict[str, Any]:
        """Calculate efficiency and performance metrics"""
        metrics = {}
        
        # CPU Efficiency Metrics
        total_cycles = self._get_stat_value('system.cpu.numCycles', int) or 0
        total_instructions = self._get_stat_value('system.cpu.commitStats0.numInsts', int) or 0
        sim_seconds = self._get_stat_value('simSeconds', float) or 0
        
        if total_cycles > 0:
            # CPU Utilization (theoretical max vs actual)
            ideal_cycles = total_instructions  # 1 cycle per instruction ideal
            cpu_utilization = (ideal_cycles / total_cycles) * 100
            metrics['cpu_utilization'] = round(cpu_utilization, 2)
            
            # Instruction Throughput
            if sim_seconds > 0:
                instructions_per_second = total_instructions / sim_seconds
                metrics['instructions_per_second'] = round(instructions_per_second, 0)
                metrics['mips'] = round(instructions_per_second / 1000000, 2)
        
        # Memory Efficiency Metrics
        memory_refs = self._get_stat_value('system.cpu.executeStats0.numMemRefs', int) or 0
        read_reqs = self._get_stat_value('system.mem_ctrls.readReqs', int) or 0
        write_reqs = self._get_stat_value('system.mem_ctrls.writeReqs', int) or 0
        
        if memory_refs > 0:
            memory_intensity = (memory_refs / total_instructions) * 100
            metrics['memory_intensity'] = round(memory_intensity, 2)
            
            # Memory access ratio
            if write_reqs > 0:
                read_write_ratio = read_reqs / write_reqs
                metrics['read_write_ratio'] = round(read_write_ratio, 2)
        
        # TLB Efficiency
        dtlb_accesses = self._get_stat_value('system.cpu.mmu.dtb.rdAccesses', int) or 0
        dtlb_accesses += self._get_stat_value('system.cpu.mmu.dtb.wrAccesses', int) or 0
        dtlb_misses = self._get_stat_value('system.cpu.mmu.dtb.rdMisses', int) or 0
        dtlb_misses += self._get_stat_value('system.cpu.mmu.dtb.wrMisses', int) or 0
        
        if dtlb_accesses > 0:
            dtlb_hit_rate = ((dtlb_accesses - dtlb_misses) / dtlb_accesses) * 100
            metrics['dtlb_hit_rate'] = round(dtlb_hit_rate, 2)
            metrics['dtlb_miss_rate'] = round(100 - dtlb_hit_rate, 2)
        
        # Register Usage Efficiency
        int_reg_reads = self._get_stat_value('system.cpu.executeStats0.numIntRegReads', int) or 0
        int_reg_writes = self._get_stat_value('system.cpu.executeStats0.numIntRegWrites', int) or 0
        fp_reg_reads = self._get_stat_value('system.cpu.executeStats0.numFpRegReads', int) or 0
        fp_reg_writes = self._get_stat_value('system.cpu.executeStats0.numFpRegWrites', int) or 0
        
        total_reg_ops = int_reg_reads + int_reg_writes + fp_reg_reads + fp_reg_writes
        if total_instructions > 0:
            register_intensity = (total_reg_ops / total_instructions)
            metrics['register_intensity'] = round(register_intensity, 2)
        
        # Pipeline Efficiency
        fetch_rate = self._get_stat_value('system.cpu.fetchStats0.fetchRate', float) or 0
        if fetch_rate > 0:
            metrics['fetch_efficiency'] = round(fetch_rate * 100, 2)
        
        # Memory Queue Analysis
        avg_read_queue = self._get_stat_value('system.mem_ctrls.avgRdQLen', float) or 0
        avg_write_queue = self._get_stat_value('system.mem_ctrls.avgWrQLen', float) or 0
        metrics['avg_read_queue_length'] = round(avg_read_queue, 2)
        metrics['avg_write_queue_length'] = round(avg_write_queue, 2)
        
        # Memory Bandwidth Utilization
        total_memory_requests = read_reqs + write_reqs
        if sim_seconds > 0:
            memory_bandwidth = total_memory_requests / sim_seconds
            metrics['memory_bandwidth_mbps'] = round(memory_bandwidth / 1000000, 2)
        
        return metrics
    
    def get_performance_insights(self) -> Dict[str, Any]:
        """Generate performance insights and recommendations"""
        insights = {
            'performance_issues': [],
            'recommendations': [],
            'bottlenecks': [],
            'efficiency_score': 0
        }
        
        # Get basic metrics
        cpi = self._get_stat_value('system.cpu.cpi', float) or 0
        ipc = self._get_stat_value('system.cpu.ipc', float) or 0
        dtlb_miss_rate = 0
        memory_intensity = 0
        
        # Calculate TLB miss rate
        dtlb_accesses = self._get_stat_value('system.cpu.mmu.dtb.rdAccesses', int) or 0
        dtlb_accesses += self._get_stat_value('system.cpu.mmu.dtb.wrAccesses', int) or 0
        dtlb_misses = self._get_stat_value('system.cpu.mmu.dtb.rdMisses', int) or 0
        dtlb_misses += self._get_stat_value('system.cpu.mmu.dtb.wrMisses', int) or 0
        
        if dtlb_accesses > 0:
            dtlb_miss_rate = (dtlb_misses / dtlb_accesses) * 100
        
        # Calculate memory intensity
        total_instructions = self._get_stat_value('system.cpu.commitStats0.numInsts', int) or 0
        memory_refs = self._get_stat_value('system.cpu.executeStats0.numMemRefs', int) or 0
        if total_instructions > 0:
            memory_intensity = (memory_refs / total_instructions) * 100
        
        # Performance Analysis
        if cpi > 10:
            insights['performance_issues'].append(f"High CPI ({cpi:.2f}) indicates poor instruction efficiency")
            insights['recommendations'].append("Consider optimizing instruction mix or reducing memory stalls")
        
        if ipc < 0.1:
            insights['performance_issues'].append(f"Very low IPC ({ipc:.4f}) suggests significant pipeline stalls")
            insights['recommendations'].append("Investigate branch prediction and memory latency")
        
        if dtlb_miss_rate > 5:
            insights['performance_issues'].append(f"High TLB miss rate ({dtlb_miss_rate:.2f}%)")
            insights['recommendations'].append("Consider larger TLB or better page locality")
        
        if memory_intensity > 50:
            insights['bottlenecks'].append("Memory-bound workload")
            insights['recommendations'].append("Optimize memory access patterns or increase memory bandwidth")
        
        # Calculate efficiency score (0-100)
        efficiency_score = 100
        if cpi > 5:
            efficiency_score -= min(30, (cpi - 5) * 3)
        if dtlb_miss_rate > 1:
            efficiency_score -= min(20, dtlb_miss_rate * 2)
        if memory_intensity > 30:
            efficiency_score -= min(25, (memory_intensity - 30) * 0.5)
        
        insights['efficiency_score'] = max(0, round(efficiency_score, 1))
        
        return insights
    
    def get_advanced_simulation_metrics(self) -> Dict[str, Any]:
        """Calculate advanced simulation metrics and insights"""
        metrics = {}
        
        # Get basic values
        total_instructions = self._get_stat_value('system.cpu.commitStats0.numInsts', int) or 0
        total_cycles = self._get_stat_value('system.cpu.numCycles', int) or 0
        total_ticks = self._get_stat_value('simTicks', int) or 0
        sim_seconds = self._get_stat_value('simSeconds', float) or 0
        host_seconds = self._get_stat_value('hostSeconds', float) or 0
        host_memory = self._get_stat_value('hostMemory', int) or 0
        sim_freq = self._get_stat_value('simFreq', int) or 0
        
        # Performance Efficiency Metrics
        if total_cycles > 0:
            # CPU Efficiency (ideal vs actual)
            ideal_cycles = total_instructions  # 1 cycle per instruction ideal
            cpu_efficiency = (ideal_cycles / total_cycles) * 100
            metrics['cpu_efficiency'] = round(cpu_efficiency, 2)
            
            # Pipeline Utilization
            pipeline_utilization = (total_instructions / total_cycles) * 100
            metrics['pipeline_utilization'] = round(pipeline_utilization, 2)
        
        # Simulation Performance Metrics
        if sim_seconds > 0:
            # Instructions per second
            instructions_per_second = total_instructions / sim_seconds
            metrics['instructions_per_second'] = round(instructions_per_second, 0)
            
            # MIPS (Million Instructions Per Second)
            mips = instructions_per_second / 1000000
            metrics['mips'] = round(mips, 2)
            
            # Simulation speed (simulated time vs real time)
            if host_seconds > 0:
                simulation_speed = sim_seconds / host_seconds
                metrics['simulation_speed'] = round(simulation_speed, 2)
                
                # Host efficiency
                host_efficiency = (sim_seconds / host_seconds) * 100
                metrics['host_efficiency'] = round(host_efficiency, 2)
        
        # Memory System Analysis
        memory_refs = self._get_stat_value('system.cpu.executeStats0.numMemRefs', int) or 0
        if total_instructions > 0:
            # Memory intensity
            memory_intensity = (memory_refs / total_instructions) * 100
            metrics['memory_intensity'] = round(memory_intensity, 2)
            
            # Average memory access time (cycles per memory access)
            if memory_refs > 0:
                avg_memory_access_time = total_cycles / memory_refs
                metrics['avg_memory_access_time'] = round(avg_memory_access_time, 2)
        
        # Register System Analysis
        int_reg_reads = self._get_stat_value('system.cpu.executeStats0.numIntRegReads', int) or 0
        int_reg_writes = self._get_stat_value('system.cpu.executeStats0.numIntRegWrites', int) or 0
        fp_reg_reads = self._get_stat_value('system.cpu.executeStats0.numFpRegReads', int) or 0
        fp_reg_writes = self._get_stat_value('system.cpu.executeStats0.numFpRegWrites', int) or 0
        
        total_reg_ops = int_reg_reads + int_reg_writes + fp_reg_reads + fp_reg_writes
        if total_instructions > 0:
            # Register intensity
            register_intensity = total_reg_ops / total_instructions
            metrics['register_intensity'] = round(register_intensity, 2)
            
            # Register efficiency (reads vs writes)
            total_reg_reads = int_reg_reads + fp_reg_reads
            total_reg_writes = int_reg_writes + fp_reg_writes
            if total_reg_writes > 0:
                reg_read_write_ratio = total_reg_reads / total_reg_writes
                metrics['reg_read_write_ratio'] = round(reg_read_write_ratio, 2)
        
        # System Resource Utilization
        if host_memory > 0:
            # Memory efficiency (instructions per MB of host memory)
            memory_efficiency = total_instructions / (host_memory / 1024 / 1024)
            metrics['memory_efficiency'] = round(memory_efficiency, 0)
        
        # Clock and Frequency Analysis
        if sim_freq > 0 and total_ticks > 0:
            # Effective clock frequency
            effective_freq = total_ticks / sim_seconds if sim_seconds > 0 else 0
            metrics['effective_freq_ghz'] = round(effective_freq / 1000000000, 2)
            
            # Clock efficiency
            clock_efficiency = (sim_seconds * sim_freq) / total_ticks * 100
            metrics['clock_efficiency'] = round(clock_efficiency, 2)
        
        # Workload Characteristics
        if total_instructions > 0:
            # Instruction density (instructions per tick)
            instruction_density = total_instructions / total_ticks
            metrics['instruction_density'] = round(instruction_density * 1000000, 2)  # per million ticks
            
            # Cycle density (cycles per tick)
            cycle_density = total_cycles / total_ticks
            metrics['cycle_density'] = round(cycle_density * 1000000, 2)  # per million ticks
        
        return metrics
    
    def get_simulation_insights(self) -> Dict[str, Any]:
        """Generate simulation insights and recommendations"""
        insights = {
            'performance_analysis': [],
            'bottlenecks': [],
            'recommendations': [],
            'workload_characteristics': [],
            'efficiency_score': 0
        }
        
        # Get metrics
        cpi = self._get_stat_value('system.cpu.cpi', float) or 0
        ipc = self._get_stat_value('system.cpu.ipc', float) or 0
        total_instructions = self._get_stat_value('system.cpu.commitStats0.numInsts', int) or 0
        total_cycles = self._get_stat_value('system.cpu.numCycles', int) or 0
        memory_refs = self._get_stat_value('system.cpu.executeStats0.numMemRefs', int) or 0
        
        # Performance Analysis
        if cpi > 100:
            insights['performance_analysis'].append(f"Very high CPI ({cpi:.2f}) indicates severe performance issues")
            insights['bottlenecks'].append("CPU pipeline stalls")
        elif cpi > 10:
            insights['performance_analysis'].append(f"High CPI ({cpi:.2f}) suggests performance bottlenecks")
            insights['bottlenecks'].append("Memory or pipeline stalls")
        
        if ipc < 0.01:
            insights['performance_analysis'].append(f"Extremely low IPC ({ipc:.4f}) indicates major inefficiencies")
            insights['bottlenecks'].append("Pipeline inefficiency")
        elif ipc < 0.1:
            insights['performance_analysis'].append(f"Low IPC ({ipc:.4f}) suggests pipeline stalls")
        
        # Memory Analysis
        if total_instructions > 0:
            memory_intensity = (memory_refs / total_instructions) * 100
            if memory_intensity > 50:
                insights['workload_characteristics'].append("Memory-intensive workload")
                insights['bottlenecks'].append("Memory bandwidth")
            elif memory_intensity > 30:
                insights['workload_characteristics'].append("Moderate memory usage")
            else:
                insights['workload_characteristics'].append("Compute-intensive workload")
        
        # Recommendations
        if cpi > 10:
            insights['recommendations'].append("Optimize instruction mix and reduce memory stalls")
        if ipc < 0.1:
            insights['recommendations'].append("Investigate branch prediction and pipeline efficiency")
        if memory_intensity > 40:
            insights['recommendations'].append("Consider memory hierarchy optimization")
        
        # Calculate efficiency score
        efficiency_score = 100
        if cpi > 5:
            efficiency_score -= min(40, (cpi - 5) * 4)
        if ipc < 0.1:
            efficiency_score -= min(30, (0.1 - ipc) * 300)
        if memory_intensity > 50:
            efficiency_score -= min(20, (memory_intensity - 50) * 0.4)
        
        insights['efficiency_score'] = max(0, round(efficiency_score, 1))
        
        return insights
    
    def _detect_architecture(self) -> str:
        """Detect CPU architecture from stats"""
        # Check for ARM indicators
        if any('arm' in key.lower() for key in self.stats_data.keys()):
            return 'ARM'
        
        # Check for x86 indicators
        if any('x86' in key.lower() or 'intel' in key.lower() for key in self.stats_data.keys()):
            return 'x86'
        
        # Check for RISC-V indicators
        if any('riscv' in key.lower() or 'risc' in key.lower() for key in self.stats_data.keys()):
            return 'RISC-V'
        
        # Default based on common patterns
        if 'system.cpu' in str(self.stats_data.keys()):
            return 'Generic'
        
        return 'Unknown'
    
    def get_memory_system_stats(self) -> Dict[str, Any]:
        """Get memory system statistics"""
        memory_stats = {}
        
        # Memory controller stats
        memory_keys = [
            'system.mem_ctrls.readReqs',
            'system.mem_ctrls.writeReqs',
            'system.mem_ctrls.readBursts',
            'system.mem_ctrls.writeBursts',
            'system.mem_ctrls.avgRdQLen',
            'system.mem_ctrls.avgWrQLen',
            'system.mem_ctrls.rdMisses',
            'system.mem_ctrls.wrMisses'
        ]
        
        for key in memory_keys:
            value = self._get_stat_value(key, int)
            if value is not None:
                memory_stats[key] = value
        
        # TLB stats
        tlb_keys = [
            'system.cpu.mmu.dtb.rdAccesses',
            'system.cpu.mmu.dtb.wrAccesses',
            'system.cpu.mmu.dtb.rdMisses',
            'system.cpu.mmu.dtb.wrMisses',
            'system.cpu.mmu.itb.rdAccesses',
            'system.cpu.mmu.itb.wrAccesses',
            'system.cpu.mmu.itb.rdMisses',
            'system.cpu.mmu.itb.wrMisses'
        ]
        
        for key in tlb_keys:
            value = self._get_stat_value(key, int)
            if value is not None:
                memory_stats[key] = value
        
        return memory_stats
    
    def get_cache_metrics(self) -> Dict[str, Any]:
        """Get cache hit/miss ratios and statistics"""
        cache_metrics = {}
        
        # TLB Cache Statistics
        dtlb_rd_accesses = self._get_stat_value('system.cpu.mmu.dtb.rdAccesses', int) or 0
        dtlb_wr_accesses = self._get_stat_value('system.cpu.mmu.dtb.wrAccesses', int) or 0
        dtlb_rd_misses = self._get_stat_value('system.cpu.mmu.dtb.rdMisses', int) or 0
        dtlb_wr_misses = self._get_stat_value('system.cpu.mmu.dtb.wrMisses', int) or 0
        
        itlb_rd_accesses = self._get_stat_value('system.cpu.mmu.itb.rdAccesses', int) or 0
        itlb_wr_accesses = self._get_stat_value('system.cpu.mmu.itb.wrAccesses', int) or 0
        itlb_rd_misses = self._get_stat_value('system.cpu.mmu.itb.rdMisses', int) or 0
        itlb_wr_misses = self._get_stat_value('system.cpu.mmu.itb.wrMisses', int) or 0
        
        # Calculate TLB Hit/Miss Rates
        dtlb_total_accesses = dtlb_rd_accesses + dtlb_wr_accesses
        dtlb_total_misses = dtlb_rd_misses + dtlb_wr_misses
        
        if dtlb_total_accesses > 0:
            dtlb_hit_rate = ((dtlb_total_accesses - dtlb_total_misses) / dtlb_total_accesses) * 100
            cache_metrics['dtlb_hit_rate'] = round(dtlb_hit_rate, 2)
            cache_metrics['dtlb_miss_rate'] = round(100 - dtlb_hit_rate, 2)
            cache_metrics['dtlb_total_accesses'] = dtlb_total_accesses
            cache_metrics['dtlb_total_misses'] = dtlb_total_misses
        
        itlb_total_accesses = itlb_rd_accesses + itlb_wr_accesses
        itlb_total_misses = itlb_rd_misses + itlb_wr_misses
        
        if itlb_total_accesses > 0:
            itlb_hit_rate = ((itlb_total_accesses - itlb_total_misses) / itlb_total_accesses) * 100
            cache_metrics['itlb_hit_rate'] = round(itlb_hit_rate, 2)
            cache_metrics['itlb_miss_rate'] = round(100 - itlb_hit_rate, 2)
            cache_metrics['itlb_total_accesses'] = itlb_total_accesses
            cache_metrics['itlb_total_misses'] = itlb_total_misses
        
        # Memory Controller Cache Statistics (Row Buffer Hit/Miss)
        read_row_hits = self._get_stat_value('system.mem_ctrls.dram.readRowHits', int) or 0
        write_row_hits = self._get_stat_value('system.mem_ctrls.dram.writeRowHits', int) or 0
        read_row_hit_rate = self._get_stat_value('system.mem_ctrls.dram.readRowHitRate', float) or 0
        write_row_hit_rate = self._get_stat_value('system.mem_ctrls.dram.writeRowHitRate', float) or 0
        page_hit_rate = self._get_stat_value('system.mem_ctrls.dram.pageHitRate', float) or 0
        
        cache_metrics['memory_read_row_hits'] = read_row_hits
        cache_metrics['memory_write_row_hits'] = write_row_hits
        cache_metrics['memory_read_row_hit_rate'] = round(read_row_hit_rate, 2)
        cache_metrics['memory_write_row_hit_rate'] = round(write_row_hit_rate, 2)
        cache_metrics['memory_page_hit_rate'] = round(page_hit_rate, 2)
        
        # Calculate memory row miss rates
        cache_metrics['memory_read_row_miss_rate'] = round(100 - read_row_hit_rate, 2)
        cache_metrics['memory_write_row_miss_rate'] = round(100 - write_row_hit_rate, 2)
        cache_metrics['memory_page_miss_rate'] = round(100 - page_hit_rate, 2)
        
        # Snoop Filter Cache Statistics
        snoop_hit_single = self._get_stat_value('system.membus.snoop_filter.hitSingleRequests', int) or 0
        snoop_hit_multi = self._get_stat_value('system.membus.snoop_filter.hitMultiRequests', int) or 0
        snoop_miss = self._get_stat_value('system.membus.snoop_filter.missRequests', int) or 0
        
        cache_metrics['snoop_hit_single'] = snoop_hit_single
        cache_metrics['snoop_hit_multi'] = snoop_hit_multi
        cache_metrics['snoop_miss'] = snoop_miss
        
        # Calculate snoop hit rate
        total_snoop_requests = snoop_hit_single + snoop_hit_multi + snoop_miss
        if total_snoop_requests > 0:
            snoop_hit_rate = ((snoop_hit_single + snoop_hit_multi) / total_snoop_requests) * 100
            cache_metrics['snoop_hit_rate'] = round(snoop_hit_rate, 2)
            cache_metrics['snoop_miss_rate'] = round(100 - snoop_hit_rate, 2)
        
        # Cache Performance Analysis
        cache_metrics['cache_performance'] = self._analyze_cache_performance(cache_metrics)
        
        return cache_metrics
    
    def _analyze_cache_performance(self, cache_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze cache performance and provide insights"""
        analysis = {
            'overall_score': 0,
            'issues': [],
            'recommendations': []
        }
        
        score = 0
        
        # TLB Performance Analysis
        dtlb_hit_rate = cache_metrics.get('dtlb_hit_rate', 0)
        itlb_hit_rate = cache_metrics.get('itlb_hit_rate', 0)
        
        if dtlb_hit_rate > 95:
            score += 25
        elif dtlb_hit_rate > 90:
            score += 20
        elif dtlb_hit_rate > 80:
            score += 15
        else:
            analysis['issues'].append(f"Low DTLB hit rate: {dtlb_hit_rate}%")
            analysis['recommendations'].append("Consider increasing DTLB size or improving page table management")
        
        if itlb_hit_rate > 95:
            score += 25
        elif itlb_hit_rate > 90:
            score += 20
        elif itlb_hit_rate > 80:
            score += 15
        else:
            analysis['issues'].append(f"Low ITLB hit rate: {itlb_hit_rate}%")
            analysis['recommendations'].append("Consider increasing ITLB size or improving instruction page locality")
        
        # Memory Row Buffer Performance
        page_hit_rate = cache_metrics.get('memory_page_hit_rate', 0)
        if page_hit_rate > 90:
            score += 30
        elif page_hit_rate > 80:
            score += 25
        elif page_hit_rate > 70:
            score += 20
        else:
            analysis['issues'].append(f"Low memory page hit rate: {page_hit_rate}%")
            analysis['recommendations'].append("Consider optimizing memory access patterns or increasing row buffer size")
        
        # Snoop Filter Performance
        snoop_hit_rate = cache_metrics.get('snoop_hit_rate', 0)
        if snoop_hit_rate > 80:
            score += 20
        elif snoop_hit_rate > 60:
            score += 15
        else:
            analysis['issues'].append(f"Low snoop filter hit rate: {snoop_hit_rate}%")
            analysis['recommendations'].append("Consider optimizing cache coherence protocols")
        
        analysis['overall_score'] = min(100, score)
        
        return analysis
    
    def _get_binary_info(self) -> Dict[str, Any]:
        """Get binary and architecture information from config.json"""
        binary_info = {
            'executable': 'Unknown',
            'architecture': 'Unknown',
            'isa': 'Unknown',
            'cpu_type': 'Unknown',
            'cpu_name': 'Unknown'
        }
        
        try:
            config_path = os.path.join(self.m5out_path, 'config.json')
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    config = json.load(f)
                
                # Extract executable path
                if 'system' in config and 'cpu' in config['system']:
                    cpu_config = config['system']['cpu']
                    if isinstance(cpu_config, list) and len(cpu_config) > 0:
                        cpu = cpu_config[0]
                        
                        # Get executable from workload
                        if 'workload' in cpu and 'executable' in cpu['workload']:
                            executable_path = cpu['workload']['executable']
                            binary_info['executable'] = os.path.basename(executable_path)
                        
                        # Get ISA information
                        if 'isa' in cpu and isinstance(cpu['isa'], list) and len(cpu['isa']) > 0:
                            isa_config = cpu['isa'][0]
                            if 'cxx_class' in isa_config:
                                isa_class = isa_config['cxx_class']
                                if 'X86ISA' in isa_class:
                                    binary_info['architecture'] = 'x86_64'
                                    binary_info['isa'] = 'X86'
                                elif 'ArmISA' in isa_class:
                                    binary_info['architecture'] = 'ARM'
                                    binary_info['isa'] = 'ARM'
                                elif 'RiscvISA' in isa_class:
                                    binary_info['architecture'] = 'RISC-V'
                                    binary_info['isa'] = 'RISC-V'
                        
                        # Get CPU type and name
                        if 'cxx_class' in cpu:
                            cpu_class = cpu['cxx_class']
                            if 'TimingSimpleCPU' in cpu_class:
                                binary_info['cpu_type'] = 'Timing Simple CPU'
                            elif 'O3CPU' in cpu_class:
                                binary_info['cpu_type'] = 'Out-of-Order CPU'
                            elif 'MinorCPU' in cpu_class:
                                binary_info['cpu_type'] = 'Minor CPU'
                        
                        # Get CPU name from ISA
                        if 'isa' in cpu and isinstance(cpu['isa'], list) and len(cpu['isa']) > 0:
                            isa_config = cpu['isa'][0]
                            if 'name_string' in isa_config:
                                binary_info['cpu_name'] = isa_config['name_string']
        
        except Exception as e:
            logger.warning(f"Could not extract binary info from config: {e}")
        
        return binary_info
    
    def _find_spill_stats_file(self) -> str:
        """Find spill stats file automatically (x86_spill_stats.txt, arm_spill_stats.txt, etc.)"""
        try:
            # Look for spill stats files in m5out directory
            spill_patterns = [
                "x86_spill_stats.txt",
                "arm_spill_stats.txt", 
                "riscv_spill_stats.txt",
                "spill_stats.txt",
                "spill_log.txt"  # fallback
            ]
            
            for pattern in spill_patterns:
                spill_file_path = os.path.join(self.m5out_path, pattern)
                if os.path.exists(spill_file_path):
                    logger.info(f"Found spill stats file: {pattern}")
                    return spill_file_path
            
            # Also check parent directory (in case spill stats is in project root)
            for pattern in spill_patterns:
                spill_file_path = os.path.join(os.path.dirname(self.m5out_path), pattern)
                if os.path.exists(spill_file_path):
                    logger.info(f"Found spill stats file in parent directory: {pattern}")
                    return spill_file_path
            
            logger.warning("No spill stats file found")
            return None
            
        except Exception as e:
            logger.error(f"Error finding spill stats file: {e}")
            return None
    
    def _detect_architecture_from_filename(self, file_path: str) -> str:
        """Detect architecture from spill stats filename"""
        filename = os.path.basename(file_path).lower()
        
        if 'x86' in filename:
            return 'x86_64'
        elif 'arm' in filename:
            return 'ARM'
        elif 'riscv' in filename or 'risc-v' in filename:
            return 'RISC-V'
        else:
            return 'Unknown'
    
    def parse_spill_log(self, spill_log_path: str) -> List[Dict[str, Any]]:
        """Parse spill log file and return structured data"""
        spill_events = []
        
        try:
            if not os.path.exists(spill_log_path):
                logger.warning(f"Spill log file not found: {spill_log_path}")
                return spill_events
            
            with open(spill_log_path, 'r') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    
                    # Skip comments and empty lines
                    if not line or line.startswith('#'):
                        continue
                    
                    # Parse spill data
                    if line.startswith('SPILL,'):
                        parts = line.split(',')
                        if len(parts) >= 9:
                            try:
                                spill_event = {
                                    'store_pc': parts[1],
                                    'load_pc': parts[2],
                                    'memory_address': parts[3],
                                    'store_tick': int(parts[4]),
                                    'load_tick': int(parts[5]),
                                    'tick_diff': int(parts[6]),
                                    'store_inst_count': int(parts[7]),
                                    'load_inst_count': int(parts[8]),
                                    'line_number': line_num
                                }
                                spill_events.append(spill_event)
                            except (ValueError, IndexError) as e:
                                logger.warning(f"Error parsing line {line_num}: {e}")
                                continue
            
            logger.info(f"Parsed {len(spill_events)} spill events from {spill_log_path}")
            return spill_events
            
        except Exception as e:
            logger.error(f"Error parsing spill log: {e}")
            return spill_events

    def get_spill_analysis_data(self) -> Dict[str, Any]:
        """Get comprehensive spill analysis data"""
        try:
            # Look for spill stats file (x86_spill_stats.txt, arm_spill_stats.txt, riscv_spill_stats.txt, etc.)
            spill_log_path = self._find_spill_stats_file()
            spill_events = self.parse_spill_log(spill_log_path) if spill_log_path else []
            
            if not spill_events:
                return {
                    'spill_count': 0,
                    'architecture': 'Unknown',
                    'spill_file': 'None',
                    'statistics': {
                        'total_spills': 0,
                        'avg_spill_duration': 0,
                        'unique_memory_addresses': 0,
                        'unique_store_pcs': 0,
                        'unique_load_pcs': 0,
                        'max_spill_duration': 0,
                        'min_spill_duration': 0
                    }
                }
            
            # Calculate statistics
            total_spills = len(spill_events)
            avg_spill_duration = sum(event['tick_diff'] for event in spill_events) / total_spills if total_spills > 0 else 0
            
            # Extract memory addresses and PC patterns
            memory_addresses = [int(event['memory_address'], 16) for event in spill_events]
            store_pcs = [int(event['store_pc'], 16) for event in spill_events]
            load_pcs = [int(event['load_pc'], 16) for event in spill_events]
            
            # Group memory addresses by ranges
            memory_ranges = {}
            for addr in memory_addresses:
                range_key = (addr // 1024) * 1024  # 1KB buckets
                memory_ranges[range_key] = memory_ranges.get(range_key, 0) + 1
            
            # Group PC patterns
            pc_patterns = {}
            for event in spill_events:
                pattern_key = f"{event['store_pc']}->{event['load_pc']}"
                pc_patterns[pattern_key] = pc_patterns.get(pattern_key, 0) + 1
            
            # Create scatter plot data
            scatter_plots = {
                'spill_timing': {
                    'title': 'Spill Timing Analysis',
                    'x_label': 'Store Instruction Count',
                    'y_label': 'Spill Duration (Ticks)',
                    'description': 'Relationship between instruction execution and spill duration',
                    'data': [
                        {
                            'x': event['store_inst_count'],
                            'y': event['tick_diff'],
                            'group': 'Spill Event',
                            'color': '#ef4444',
                            'size': 12,
                            'details': {
                                'store_pc': event['store_pc'],
                                'load_pc': event['load_pc'],
                                'memory_address': event['memory_address'],
                                'duration_ticks': event['tick_diff'],
                                'instruction_gap': event['load_inst_count'] - event['store_inst_count']
                            }
                        } for event in spill_events
                    ]
                },
                'memory_distribution': {
                    'title': 'Memory Address Distribution',
                    'x_label': 'Memory Address (Hex)',
                    'y_label': 'Spill Count',
                    'description': 'Distribution of spills across memory addresses',
                    'data': [
                        {
                            'x': addr,
                            'y': count,
                            'group': 'Memory Range',
                            'color': '#3b82f6',
                            'size': 15,
                            'details': {
                                'memory_range': f"0x{addr:x}",
                                'spill_count': count,
                                'range_size': '1KB'
                            }
                        } for addr, count in memory_ranges.items()
                    ]
                },
                'pc_correlation': {
                    'title': 'PC Correlation Analysis',
                    'x_label': 'Store PC (Hex)',
                    'y_label': 'Load PC (Hex)',
                    'description': 'Correlation between store and load program counters',
                    'data': [
                        {
                            'x': int(event['store_pc'], 16),
                            'y': int(event['load_pc'], 16),
                            'group': 'PC Pair',
                            'color': '#10b981',
                            'size': 10,
                            'details': {
                                'store_pc': event['store_pc'],
                                'load_pc': event['load_pc'],
                                'pc_distance': int(event['load_pc'], 16) - int(event['store_pc'], 16),
                                'memory_address': event['memory_address']
                            }
                        } for event in spill_events
                    ]
                }
            }
            
            # Create heatmap data
            heatmaps = {
                'memory_heatmap': {
                    'title': 'Memory Address Heatmap',
                    'x_label': 'Memory Address Range',
                    'y_label': 'Spill Frequency',
                    'description': 'Heatmap showing spill frequency across memory ranges',
                    'data': [
                        {
                            'x': addr,
                            'y': 0,
                            'value': count,
                            'group': 'Memory Range',
                            'color': self._get_heatmap_color(count, max(memory_ranges.values())),
                            'details': {
                                'memory_range': f"0x{addr:x}",
                                'spill_count': count,
                                'percentage': (count / total_spills * 100) if total_spills > 0 else 0
                            }
                        } for addr, count in memory_ranges.items()
                    ]
                },
                'timing_heatmap': {
                    'title': 'Spill Timing Heatmap',
                    'x_label': 'Store Instruction Count',
                    'y_label': 'Load Instruction Count',
                    'description': 'Heatmap showing spill timing patterns',
                    'data': [
                        {
                            'x': event['store_inst_count'],
                            'y': event['load_inst_count'],
                            'value': event['tick_diff'],
                            'group': 'Timing Pattern',
                            'color': self._get_heatmap_color(event['tick_diff'], max(event['tick_diff'] for event in spill_events)),
                            'details': {
                                'store_inst': event['store_inst_count'],
                                'load_inst': event['load_inst_count'],
                                'instruction_gap': event['load_inst_count'] - event['store_inst_count'],
                                'tick_duration': event['tick_diff']
                            }
                        } for event in spill_events
                    ]
                }
            }
            
            # Detect architecture from filename
            architecture = self._detect_architecture_from_filename(spill_log_path)
            
            # Calculate performance impact metrics
            total_instructions = self._get_stat_value('simInsts', int) or 0
            total_cycles = self._get_stat_value('system.cpu.numCycles', int) or 0
            total_memory_refs = self._get_stat_value('system.cpu.commitStats0.numMemRefs', int) or 0
            total_loads = self._get_stat_value('system.cpu.commitStats0.numLoadInsts', int) or 0
            total_stores = self._get_stat_value('system.cpu.commitStats0.numStoreInsts', int) or 0
            
            # Calculate spill impact
            spill_memory_refs = total_spills * 2  # Each spill has store + load
            normal_memory_refs = (total_loads + total_stores) - spill_memory_refs
            
            # Calculate spill cycles
            total_spill_cycles = sum(event['tick_diff'] for event in spill_events)
            # Ensure normal cycles is not negative (spill cycles might be larger than total cycles)
            normal_cycles = max(0, total_cycles - total_spill_cycles)
            
            # Calculate CPI breakdown
            spill_cpi = (total_spill_cycles / total_instructions) if total_instructions > 0 else 0
            normal_cpi = (normal_cycles / total_instructions) if total_instructions > 0 else 0
            total_cpi = spill_cpi + normal_cpi
            
            # Calculate performance loss percentage
            performance_loss_percentage = (spill_cpi / total_cpi * 100) if total_cpi > 0 else 0
            
            # Generate detailed analysis data for better charts
            detailed_charts = self._generate_detailed_charts(spill_events, total_instructions, total_cycles)
            
            return {
                'spill_count': total_spills,
                'architecture': architecture,
                'spill_file': os.path.basename(spill_log_path),
                'statistics': {
                    'total_spills': total_spills,
                    'avg_spill_duration': avg_spill_duration,
                    'unique_memory_addresses': len(set(memory_addresses)),
                    'unique_store_pcs': len(set(store_pcs)),
                    'unique_load_pcs': len(set(load_pcs)),
                    'max_spill_duration': max(event['tick_diff'] for event in spill_events) if spill_events else 0,
                    'min_spill_duration': min(event['tick_diff'] for event in spill_events) if spill_events else 0
                },
                'charts': detailed_charts
            }
            
        except Exception as e:
            logger.error(f"Error generating spill analysis data: {e}")
            return {
                'spill_count': 0,
                'architecture': 'unknown',
                'spill_file': 'none',
                'statistics': {
                    'total_spills': 0,
                    'avg_spill_duration': 0,
                    'unique_memory_addresses': 0,
                    'unique_store_pcs': 0,
                    'unique_load_pcs': 0,
                    'max_spill_duration': 0,
                    'min_spill_duration': 0
                },
                'charts': {}
            }
        """Generate detailed chart data for meaningful visualizations"""
        if not spill_events:
            return {}
        
        # 1. Spill Duration Distribution (Histogram)
        durations = [event['tick_diff'] for event in spill_events]
        duration_buckets = self._create_histogram_buckets(durations, 20)
        
        # 2. Memory Address Distribution (Sample for visualization)
        memory_addresses = [event['memory_address'] for event in spill_events]
        address_distribution = self._analyze_memory_address_distribution(memory_addresses)
        
        # 3. Instruction Distance Analysis (Store to Load distance)
        instruction_distances = [event['load_inst_count'] - event['store_inst_count'] for event in spill_events]
        distance_buckets = self._create_histogram_buckets(instruction_distances, 15)
        
        # 4. PC Pattern Analysis (Most frequent spill locations)
        pc_patterns = self._analyze_pc_patterns(spill_events)
        
        # 5. Timeline Analysis (Spill distribution over time)
        timeline_data = self._analyze_spill_timeline(spill_events)
        
        return {
            'spill_duration_distribution': {
                'title': 'Spill Duration Distribution',
                'description': 'Distribution of spill durations (ticks)',
                'buckets': duration_buckets,
                'total_spills': len(spill_events),
                'avg_duration': sum(durations) / len(durations),
                'min_duration': min(durations),
                'max_duration': max(durations)
            },
            'memory_address_distribution': {
                'title': 'Memory Address Distribution',
                'description': 'Distribution of spill memory addresses',
                'data': address_distribution,
                'unique_addresses': len(set(memory_addresses)),
                'total_spills': len(spill_events)
            },
            'instruction_distance_analysis': {
                'title': 'Instruction Distance Analysis',
                'description': 'Distance between store and load instructions',
                'buckets': distance_buckets,
                'avg_distance': sum(instruction_distances) / len(instruction_distances),
                'min_distance': min(instruction_distances),
                'max_distance': max(instruction_distances)
            },
            'pc_pattern_analysis': {
                'title': 'PC Pattern Analysis',
                'description': 'Most frequent spill locations',
                'patterns': pc_patterns,
                'total_unique_pcs': len(set([event['store_pc'] for event in spill_events]))
            },
            'timeline_analysis': {
                'title': 'Spill Timeline Analysis',
                'description': 'Spill distribution over simulation time',
                'data': timeline_data,
                'total_time_span': max([event['load_tick'] for event in spill_events]) - min([event['store_tick'] for event in spill_events])
            }
        }
    
    def _create_histogram_buckets(self, data, num_buckets):
        """Create histogram buckets for data visualization"""
        if not data:
            return []
        
        min_val = min(data)
        max_val = max(data)
        bucket_size = (max_val - min_val) / num_buckets if max_val > min_val else 1
        
        buckets = []
        for i in range(num_buckets):
            bucket_start = min_val + i * bucket_size
            bucket_end = min_val + (i + 1) * bucket_size
            count = sum(1 for val in data if bucket_start <= val < bucket_end)
            
            buckets.append({
                'range': f"{int(bucket_start):,} - {int(bucket_end):,}",
                'count': count,
                'percentage': (count / len(data)) * 100,
                'start': bucket_start,
                'end': bucket_end
            })
        
        return buckets
    
    def _analyze_memory_address_distribution(self, memory_addresses):
        """Analyze memory address distribution"""
        # Convert hex addresses to integers for analysis
        int_addresses = [int(addr, 16) for addr in memory_addresses]
        
        # Group addresses by ranges
        min_addr = min(int_addresses)
        max_addr = max(int_addresses)
        range_size = (max_addr - min_addr) // 10  # 10 ranges
        
        ranges = []
        for i in range(10):
            start = min_addr + i * range_size
            end = min_addr + (i + 1) * range_size
            count = sum(1 for addr in int_addresses if start <= addr < end)
            
            ranges.append({
                'range': f"0x{start:x} - 0x{end:x}",
                'count': count,
                'percentage': (count / len(memory_addresses)) * 100,
                'start': start,
                'end': end
            })
        
        return ranges
    
    def _analyze_pc_patterns(self, spill_events):
        """Analyze PC patterns for spill locations"""
        store_pc_counts = {}
        load_pc_counts = {}
        
        for event in spill_events:
            store_pc = event['store_pc']
            load_pc = event['load_pc']
            
            store_pc_counts[store_pc] = store_pc_counts.get(store_pc, 0) + 1
            load_pc_counts[load_pc] = load_pc_counts.get(load_pc, 0) + 1
        
        # Get top 10 most frequent PCs
        top_store_pcs = sorted(store_pc_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        top_load_pcs = sorted(load_pc_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return {
            'top_store_pcs': [{'pc': pc, 'count': count} for pc, count in top_store_pcs],
            'top_load_pcs': [{'pc': pc, 'count': count} for pc, count in top_load_pcs]
        }
    
    def _analyze_spill_timeline(self, spill_events):
        """Analyze spill distribution over time"""
        # Group spills by time windows
        store_times = [event['store_tick'] for event in spill_events]
        min_time = min(store_times)
        max_time = max(store_times)
        time_window = (max_time - min_time) // 20  # 20 time windows
        
        timeline = []
        for i in range(20):
            window_start = min_time + i * time_window
            window_end = min_time + (i + 1) * time_window
            count = sum(1 for time in store_times if window_start <= time < window_end)
            
            timeline.append({
                'time_window': f"{int(window_start):,} - {int(window_end):,}",
                'count': count,
                'start_time': window_start,
                'end_time': window_end
            })
        
        return timeline

    def _get_heatmap_color(self, value: int, max_value: int) -> str:
        """Get color for heatmap based on value intensity"""
        if max_value == 0:
            return '#f3f4f6'
        
        intensity = value / max_value
        
        if intensity < 0.2:
            return '#dbeafe'  # Light blue
        elif intensity < 0.4:
            return '#93c5fd'  # Medium blue
        elif intensity < 0.6:
            return '#3b82f6'  # Blue
        elif intensity < 0.8:
            return '#1d4ed8'  # Dark blue
        else:
            return '#1e40af'  # Darker blue

    def get_scatter_plot_data(self) -> Dict[str, Any]:
        """Get scatter plot data for performance analysis"""
        try:
            # Get basic metrics
            cpi = self._get_stat_value('system.cpu.cpi', float) or 0
            ipc = self._get_stat_value('system.cpu.ipc', float) or 0
            total_instructions = self._get_stat_value('simInsts', int) or 0
            total_loads = self._get_stat_value('system.cpu.commitStats0.numLoadInsts', int) or 0
            total_stores = self._get_stat_value('system.cpu.commitStats0.numStoreInsts', int) or 0
            total_memory_refs = total_loads + total_stores
            
            # Calculate memory reference percentage
            memory_ref_percentage = (total_memory_refs / total_instructions * 100) if total_instructions > 0 else 0
            
            # Get cache metrics
            dtlb_hits = self._get_stat_value('system.cpu.mmu.dtb.hits', int) or 0
            dtlb_misses = self._get_stat_value('system.cpu.mmu.dtb.misses', int) or 0
            dtlb_total = dtlb_hits + dtlb_misses
            dtlb_miss_rate = (dtlb_misses / dtlb_total * 100) if dtlb_total > 0 else 0
            
            itlb_hits = self._get_stat_value('system.cpu.mmu.itb.hits', int) or 0
            itlb_misses = self._get_stat_value('system.cpu.mmu.itb.misses', int) or 0
            itlb_total = itlb_hits + itlb_misses
            itlb_miss_rate = (itlb_misses / itlb_total * 100) if itlb_total > 0 else 0
            
            # Get memory controller data
            read_reqs = self._get_stat_value('system.mem_ctrls.readReqs', int) or 0
            write_reqs = self._get_stat_value('system.mem_ctrls.writeReqs', int) or 0
            total_mem_reqs = read_reqs + write_reqs
            
            # Calculate memory bandwidth (simplified)
            memory_bandwidth = total_mem_reqs / (self._get_stat_value('simSeconds', float) or 1)
            
            # Get instruction type data for grouping
            int_insts = self._get_stat_value('system.cpu.commitStats0.numIntInsts', int) or 0
            fp_insts = self._get_stat_value('system.cpu.commitStats0.numFpInsts', int) or 0
            vec_insts = self._get_stat_value('system.cpu.commitStats0.numVecInsts', int) or 0
            
            # Create scatter plot data
            scatter_data = {
                'memory_performance': {
                    'title': 'Memory Access vs Performance',
                    'x_label': 'Memory Reference Percentage (%)',
                    'y_label': 'CPI (Cycles Per Instruction)',
                    'description': 'Relationship between memory access intensity and performance',
                    'data': [
                        {
                            'x': memory_ref_percentage,
                            'y': cpi,
                            'group': 'Overall',
                            'color': '#3b82f6',
                            'size': 20,
                            'details': {
                                'loads': total_loads,
                                'stores': total_stores,
                                'total_refs': total_memory_refs,
                                'instructions': total_instructions
                            }
                        },
                        {
                            'x': (total_loads / total_instructions * 100) if total_instructions > 0 else 0,
                            'y': cpi,
                            'group': 'Load Operations',
                            'color': '#10b981',
                            'size': 15,
                            'details': {
                                'load_instructions': total_loads,
                                'load_percentage': (total_loads / total_instructions * 100) if total_instructions > 0 else 0
                            }
                        },
                        {
                            'x': (total_stores / total_instructions * 100) if total_instructions > 0 else 0,
                            'y': cpi,
                            'group': 'Store Operations',
                            'color': '#f59e0b',
                            'size': 15,
                            'details': {
                                'store_instructions': total_stores,
                                'store_percentage': (total_stores / total_instructions * 100) if total_instructions > 0 else 0
                            }
                        }
                    ]
                },
                'cache_performance': {
                    'title': 'Cache Performance vs Memory Intensity',
                    'x_label': 'Cache Miss Rate (%)',
                    'y_label': 'Memory Bandwidth (Requests/sec)',
                    'description': 'Relationship between cache efficiency and memory bandwidth usage',
                    'data': [
                        {
                            'x': dtlb_miss_rate,
                            'y': memory_bandwidth,
                            'group': 'DTLB',
                            'color': '#ef4444',
                            'size': 18,
                            'details': {
                                'dtlb_hits': dtlb_hits,
                                'dtlb_misses': dtlb_misses,
                                'dtlb_total': dtlb_total,
                                'hit_rate': (dtlb_hits / dtlb_total * 100) if dtlb_total > 0 else 0
                            }
                        },
                        {
                            'x': itlb_miss_rate,
                            'y': memory_bandwidth,
                            'group': 'ITLB',
                            'color': '#8b5cf6',
                            'size': 18,
                            'details': {
                                'itlb_hits': itlb_hits,
                                'itlb_misses': itlb_misses,
                                'itlb_total': itlb_total,
                                'hit_rate': (itlb_hits / itlb_total * 100) if itlb_total > 0 else 0
                            }
                        },
                        {
                            'x': (dtlb_miss_rate + itlb_miss_rate) / 2,
                            'y': memory_bandwidth,
                            'group': 'Combined TLB',
                            'color': '#06b6d4',
                            'size': 20,
                            'details': {
                                'avg_miss_rate': (dtlb_miss_rate + itlb_miss_rate) / 2,
                                'total_tlb_accesses': dtlb_total + itlb_total
                            }
                        }
                    ]
                },
                'instruction_performance': {
                    'title': 'Instruction Types vs Performance',
                    'x_label': 'Instruction Count',
                    'y_label': 'CPI (Cycles Per Instruction)',
                    'description': 'Performance impact of different instruction types',
                    'data': [
                        {
                            'x': int_insts,
                            'y': cpi,
                            'group': 'Integer Instructions',
                            'color': '#3b82f6',
                            'size': 16,
                            'details': {
                                'instruction_type': 'Integer',
                                'count': int_insts,
                                'percentage': (int_insts / total_instructions * 100) if total_instructions > 0 else 0
                            }
                        },
                        {
                            'x': fp_insts,
                            'y': cpi,
                            'group': 'Float Instructions',
                            'color': '#10b981',
                            'size': 16,
                            'details': {
                                'instruction_type': 'Float',
                                'count': fp_insts,
                                'percentage': (fp_insts / total_instructions * 100) if total_instructions > 0 else 0
                            }
                        },
                        {
                            'x': vec_insts,
                            'y': cpi,
                            'group': 'Vector Instructions',
                            'color': '#f59e0b',
                            'size': 16,
                            'details': {
                                'instruction_type': 'Vector',
                                'count': vec_insts,
                                'percentage': (vec_insts / total_instructions * 100) if total_instructions > 0 else 0
                            }
                        }
                    ]
                }
            }
            
            return scatter_data
            
        except Exception as e:
            logger.error(f"Error generating scatter plot data: {e}")
            return {
                'memory_performance': {'title': 'Memory Access vs Performance', 'data': []},
                'cache_performance': {'title': 'Cache Performance vs Memory Intensity', 'data': []},
                'instruction_performance': {'title': 'Instruction Types vs Performance', 'data': []}
            }

    def _get_stat_value(self, key: str, value_type: type = str) -> Any:
        """Get a stat value with type conversion"""
        if key in self.stats_data:
            try:
                return value_type(self.stats_data[key])
            except (ValueError, TypeError):
                return None
        return None
